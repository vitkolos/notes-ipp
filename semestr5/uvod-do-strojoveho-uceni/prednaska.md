# Úvod do strojového učení v Pythonu

- https://ufal.mff.cuni.cz/courses/npfl129
- https://github.com/ufal/npfl129/
- Piazza
	- primární způsob komunikace
	- čte ji víc lidí než e-mail, takže je větší šance, že nám někdo odpoví
	- nedávat tam zdrojový kód (do veřejných otázek)
- bodování
	- zápočet – alespoň 70 standardních bodů
	- standardní body nad 70 se přenáší ke zkoušce
	- bonusové body lze získat soutěžemi a dalšími aktivitami nad rámec, také se přenáší ke zkoušce
- definice strojového učení
	- pomocí zkušenosti (dat) se zlepšuje metrika na nějaké úloze
	- možné úlohy: klasifikace (přiřazení vstupu do diskrétní kategorie), regrese (přiřazení reálného čísla nebo vektoru reálných čísel), předvídání struktury, odstraňování šumu
	- metriky: accuracy (jak dobře se při klasifikaci trefujeme), …
	- zkušenost
		- supervised (učení s učitelem) – máme olablovaná data
		- unsupervised (učení bez učitele) – nemáme žádné labely, učíme se vidět vzory v datech
		- reinforcement learning (zpětnovazebné učení) – např. aby byl šachový program lepší než nejlepší hráči
- základní úlohy
	- mějme vstup $x\in\mathbb R^D$
	- regrese: pro $x$ hledáme reálnou proměnnou $t\in\mathbb R$
	- klasifikace: máme $K$ labelů, pro dané $x$ chceme najít ten správný
		- můžeme určit třídu
		- můžeme určit pravděpodobnostní distribuci tříd
	- obvykle máme trénovací sadu dvojic $(x,t)$
	- rozdělíme data na trénovací a testovací – aby bylo učení dost obecné
- notace
	- tenzor je nadkrychle čísel
	- všechny vektory jsou sloupcové
		- do matic je skládáme jako řádky
- vstupní data
	- trénovací množina $X\in\mathbb R^{N\times D}$
		- $N$ instancí, každé odpovídá $D$ reálných čísel
		- dimenze vstupu = feature
	- při učení s učitelem máme target $t$ pro každou instanci
		- v regresi … $t\in\mathbb R^N$
		- v klasifikaci … $t\in\set{0,1,\dots,K-1}$

## Lineární regrese

- lineární regrese
	- $y(x;w,b)=x^Tw+b$
		- $w$ … váhy
		- $b$ … bias (jindy se označuje jako intercept)
		- protože je otrava zacházet s biasem, někdy se k vektorům přidávají na konec jedničky, takže místo $b$ máme $1\cdot w_{d+1}$
	- chceme změřit, jak se nám regrese daří
		- použijeme mean squared error (MSE) nebo taky funguje součet druhých mocnin chyb (dělený dvěma)
	- co když matice $X^TX$ není regulární? můžeme přičíst náhodný šum (dost malý)
- overfitting, underfitting
	- overfitting … model funguje dobře na trénovacích datech, ale nefunguje na testovacích datech
	- kapacita modelu – slouží k ovlivňování underfittingu a overfittingu
		- representational capacity
		- effective capacity
		- čím větší kapacita modelu, tím větší pravděpodobnost overfittingu
	- dvě křivky – chyba na trénovacích a testovacích datech
		- mezera mezi nimi = generalization gap
	- cílem je najít minimum křivky chyby na trénovacích datech
		- "sweet spot"
	- jak se zbavit overfittingu
		- použít více dat
		- regularizace – jakýkoliv krok k větší generalizaci modelu
			- příkladem regularizace je snižování kapacity modelu
	- $L^2$-regularizace
		- upřednostňuje „jednodušší“ modely, tedy ty, které mají menší váhy
		- obvykle se aplikuje na opravdové váhy, ne na bias
		- důsledkem je omezení efektivní kapacity modelu
			- pro větší lambda nám kapacita přestane stačit – daty se v podstatě proloží přímka
			- lambda … regularization rate 
		- matice, kterou nakonec použijeme, je nutně regulární, takže jsme vyřešili problém s inverzní maticí
- volba hyperparametrů
	- učící algoritmus nenastavuje hyperparametry
	- validační/vývojová sada dat se používá k určení hyperparametrů
	- takže data dělíme mezi trénovací, vývojová a testovací (obvykle v poměru 60 %, 20 %, 20 %)
	- zatím jsme měli hyperparametry $M$ (stupeň polynomu) a $\lambda$ („úroveň regularizace“)
- gradient descent
	- někdy se hodí hledat nejlepší váhy iterativně
	- hledáme $\text{arg}_w\min E(w)$
	- můžeme použít gradient descent $w\leftarrow w-\alpha\nabla_wE(w)$
	- $\alpha$ … learning rate
	- přístupy
		- standard/batch gradient descent – použijeme všechna trénovací data
		- stochastic/online gradient descent (SGD) – po jednom vybíráme náhodné příklady z trénovacích dat
			- unbiased, but noisy
		- minibatch stochastic gradient descent
	- dá se dokázat, že SGD za určitých podmínek téměř jistě konvrguje
- feature types
	- polynomial features
	- categorical one-hot features
- features je potřeba normalizovat, abychom mohli pro všechny používat stejný learning rate
	- odečtením minima a vydělením rozdílem maxima a minima data dostaneme mezi nulu a jedničku
	- velký problém jsou outliers
		- dá se to řešit standardizací
		- data budou mezi -1 a 1
		- nebo se můžeme zbavit outlierů

## Binární klasifikace

- klasifikujeme data do dvou tříd
- nejjednodušší metrika je úspěšnost (accuracy)
	- poměr správně klasifikovaných dat
- budeme hledat nadrovinu, která nám oddělí jednu třídu od druhé
	- nadrovina … $x^Tw=0$
	- jedna třída … $x^Tw>0$
	- druhá třída … $x^Tw\lt 0$
- budeme uvažovat množinu tříd $\set{-1,+1}$, tedy target $t\in \set{-1,+1}$
- $t_ix_i^Tw\gt 0$
- perceptron
- poznámka: slajdy se s *výstražnou sumou* si nemusíme pamatovat
- problémy perceptronu
	- když není vstup lineárně separovatelný, algoritmus nikdy neskončí
	- algoritmus vrátí jedinou predikci, neumí vrátit pravděpodobnosti více predikcí
	- ale hlavně, algoritmus perceptronu najde nějaké řešení, ne nutně dobré řešení, protože když už to řešení najde, nemůže ho dále měnit/zlepšovat
- teorie informace
	- vlastnosti $I(X)$
		- $P(x)=1\implies I(X)=0$
		- $P(x,y)=P(x)P(y)\implies I(x,y)=I(x)+I(y)$
		- $\forall x:I(x)\geq 0$
	- $I(x)\equiv -\log P(x)=\log\frac1{P(x)}$
	- entropie $H(P)$
	- cross-entropy $H(P,Q)\geq H(P)$
		- jak jsem překvapený, když si myslím $Q$, ale ve skutečnosti se děje $P$
	- Gibbsova nerovnost
		- $H(P,Q)\geq H(P)$
		- $H(P,Q)=H(P)\iff P=Q$
	- KL divergence
	- normální rozdělení
		- centrální limitní věta
		- princip maximální entropie
- odhad maximální věrohodnosti
	- $L(w)=p_\text{model}(X;w)=\prod_{i=1}^Np_\text{model}(x_i;w)$
